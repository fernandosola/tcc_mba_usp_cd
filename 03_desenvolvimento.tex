\section{Considerações Iniciais}

Neste capítulo pretende-se detalhar melhor o problema a ser resolvido. Posteriormente, será descrito todo o \textit{pipeline} de coleta e tratamentos dos dados para a montagem do \textit{dataset} que será utilizado para treinamento e avaliação do modelo proposto.

Ainda neste capítulo, serão descritos os experimentos realizados, métricas utilizadas e o modelo escolhido. Por fim, serão exibidos alguns resultados obtidos, a partir da utilização do modelo selecionado, em dados reais.

\section{Detalhamento do Problema}

Ao chegar uma nova denúncia através do sistema FalaBR, da OGU, uma equipe de pessoas atua para avaliar as informações presentes na denúncia e decidir se a denúncia está apta a ser apurada ou não. Ou seja, a avaliação da equipe diz respeito a elementos presentes na denúncia que permitem uma apuração dos fatos relatados.

Em geral, estes elementos estão centrados em informações como CPF, CNPJ, Contratos e Convênios entre órgãos públicos e empresas privadas, materialidade (valores monetários descritos na denúncia ou identificados nos contratos e convênios). Com tais informações, a equipe de triagem de denúncias decide se deverá haver apuração (denúncia apta) ou não (denúncia não apta).

Uma grande parte deste trabalho pode ser automatizado. Assim, as consultas realizadas pela equipe, em diversos sistemas, podem ser substituídas por um processo automatizado, desde que seja possível identificar tais entidades no conteúdo das denúncias. Além disso, durante o processo de triagem, a equipe atribui uma nota de 0 a 100 (de 10 em 10) para definir o quão apta é uma denúncia. Por definições internas, notas acima de entre 0 e 50 são consideradas não aptas e notas entre 60 e 100 são consideradas aptas. Tais notas podem ser utilizadas como rótulo para um aprendizado supervisionado.

Assim, sendo possível montar um conjunto de variáveis adequadas é possível propor a criação de um modelo para inferir notas às novas denúncias automaticamente.

O primeiro problema a ser resolvido, então, é a coleta e preparação dos dados. 
A próxima seção detalha os desafios enfrentados e como foram resolvidos.

\section{Coleta de Dados}

O processo de coleta e análise de dados para utilizar em treinamentos de aprendizado de máquina, geralmente, é composto por uma fase de análise exploratória. Em muitos casos, os dados estão estruturados e o maior trabalho é uma análise onde verifica-se duplicidades, dados faltantes, outliers e outras peculiaridades comuns em dados provenientes de sistemas informatizados. 
Já, no caso deste trabalho, não há, diretamente, dados estruturados. As únicas informações que podem ser obtidas são o texto da denúncia e os anexos, quando informados. Assim, a análise das denúncias e o seu uso para um aprendizado supervisionado devem abranger técnicas de NLP.

Como já foi mencionado, há rótulos sendo atribuídos às denúncias. Assim, o \textit{dataset} que será utilizado contém 1281 registros contendo informações da denúncia, anexos e a informação de grau de aptidão. Estes registros compreendem todas as denúncias cadastradas entre 04/12/2019 e 24/04/2020.

\begin{figure}[htbp]
\hypertarget{fig_00100_quantidade_denuncias}{
    \caption{Quantidade de denúncias por rótulo}\label{fig_00100_quantidade_denuncias}
    \begin{center}
        \includegraphics[width=\columnwidth]{images/fig_00100_quantidade_denuncias.png}
    \end{center}
}
\legend{Fonte: Autor.}
\end{figure}

Conforme pode ser visto na \autoref{fig_00100_quantidade_denuncias}, a maior parte das denúncias recebeu um grau de aptidão 10, ou seja, são denúncias as quais os especialistas da OGU não possuem dúvidas de que as situações reportadas não devem ser apuradas.

\subsection{Extração de Textos dos Anexos}

Ao avaliar os anexos presentes em todas as denúncias cadastradas, identificou-se uma variedade muito grade de tipos de arquivos. Por essa razão, implementar um código, mesmo que utilizando bibliotecas prontas em python não se provou uma alternativa viável. Não foi possível identificar nenhuma biblioteca em python que conseguisse sozinha lidar com qualquer tipo de arquivo. Por outro lado, escrever um código para identificar o tipo de arquivo e realizar a chamada para uma biblioteca especializada no tipo de arquivo em questão não seria uma tarefa trivial e fugiria demais do escopo do trabalho.

\textbf{TODO: quantitativo de anexos, tipos de anexos}

Assim, para possibilitar a extração dos textos dos anexos, optou-se por utilizar uma ferramenta chamada Apache Tika (disponível em \url{http://tika.apache.org}) implementada em java. Esta ferramenta identifica automaticamente o tipo de arquivo e extrai o conteúdo textual e os metadados. A ferramenta, ainda é capaz de realizar \sigla{OCR}{\textit{Optical Character Recognition}} quando há imagens dentro de arquivos dos tipo pdf, xls, doc, entre outros ou quando o arquivo é uma imagem.

Desta forma, configurou-se um servidor com a ferramenta instalada na forma de um serviço e utilizou-se uma biblioteca em python para realizar as chamadas ao serviço passando os arquivos que deveriam ter o conteúdo extraído.

\subsection{Extração de Dados Estruturados}

A extração de dados estruturados é a tentativa de identificar certas entidades de interesse no conteúdo do texto da denúncia e seus anexos. As entidades de interesse, neste momento são CPF, CNPJ, convênios, contratos, NIS, nomes de pessoas, palavras fortes e valores.

Apesar de haver diversas formas de reconhecimento de entidades nomeadas, por questões de escopo e tempo, decidiu-se realizar a extração destas informações utilizando expressões regulares. A implementação de regras com expressões regulares para as entidades citadas acima, é simples na maioria dos casos e não exigem um treinamento como no caso dos algoritmos mencionados no \autoref{chapter:revisao_bibliografica}.

\textbf{TODO: detalhar cada tipo de entidade e incluir o código fonte (no anexo? ou no apêndice?) para detecção e validação das entidades}

\textbf{TODO: escrever sobre a quantidade de entidades encontradas nos registros do dataset}

\subsection{Expansão das Informações}

Um especialista da OGU, ao analisar uma denúncia, pesquisa informações a partir das informações citadas. Da mesma forma, a etapa de expansão compreende todos os dados estruturados, derivados daqueles encontrados na etapa anterior. 

Por exemplo, para um CPF citado, pode-se avaliar em quais CNPJs este CPF consta como sócio. Em um CNPJ pode-se avaliar os sócios. Em contratos ou convênios pode-se querer avaliar os participantes (órgãos e CNPJs), além do valor envolvido no ato administrativo. Para um nome de pessoa citado, pode-se tentar buscar o CPF caso não haja homônimos na base de CPFs da Receita Federal. Estas informações são extraídas e armazenadas mantendo-se a hierarquia, ou seja, um CNPJ extraído por que um CPF aparece no quadro societário possui um apontamento para o CPF que o originou e a relação ``é sócio de'' é preservada. Além disso, todos os dados estruturados preservam o identificador da denúncia a qual foram extraídos.

\begin{figure}[htbp]
\hypertarget{ig_00200_extracao_expansao}{
    \caption{Processo de extração e expansão de dados estruturados}\label{ig_00200_extracao_expansao}
    \begin{center}
        \includesvg{images/fig_00200_extracao_expansao.svg}
    \end{center}
}
\legend{Fonte: Autor.}
\end{figure}

\subsection{Qualificação dos Dados Estruturados Encontrados}

\subsection{Preparação do \textit{Dataset}}

\section{Experimentos Propostos}

\section{Escolha das Métricas}

\section{Resultados dos Testes}

\section{Modelo Escolhido}

\section{Desempenho do Modelo em Produção}

